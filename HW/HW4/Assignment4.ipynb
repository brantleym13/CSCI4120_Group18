{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the breast cancer data\n",
    "init_data = load_breast_cancer()\n",
    "(X, y) = load_breast_cancer(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "# getting the shape of the dataset\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split of the data in the ratio of 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of Feature 1 with label:  -0.7256059801968108\n",
      "Correlation of Feature 2 with label:  -0.4065894050560832\n",
      "Correlation of Feature 3 with label:  -0.741853614062286\n",
      "Correlation of Feature 4 with label:  -0.7083848675544729\n",
      "Correlation of Feature 5 with label:  -0.39318582116345113\n",
      "Correlation of Feature 6 with label:  -0.6309319771528702\n",
      "Correlation of Feature 7 with label:  -0.7122789266531995\n",
      "Correlation of Feature 8 with label:  -0.7882615846959873\n",
      "Correlation of Feature 9 with label:  -0.3324446795512198\n",
      "Correlation of Feature 10 with label:  -0.025924332654916445\n",
      "Correlation of Feature 11 with label:  -0.5707563422154452\n",
      "Correlation of Feature 12 with label:  0.015363784845475995\n",
      "Correlation of Feature 13 with label:  -0.5675702605108826\n",
      "Correlation of Feature 14 with label:  -0.5774554450398077\n",
      "Correlation of Feature 15 with label:  0.04522064381388578\n",
      "Correlation of Feature 16 with label:  -0.3127983050044024\n",
      "Correlation of Feature 17 with label:  -0.25243924865243195\n",
      "Correlation of Feature 18 with label:  -0.4115483502284696\n",
      "Correlation of Feature 19 with label:  0.0338855659206667\n",
      "Correlation of Feature 20 with label:  -0.11354953171431853\n",
      "Correlation of Feature 21 with label:  -0.7749316594752199\n",
      "Correlation of Feature 22 with label:  -0.445302171283062\n",
      "Correlation of Feature 23 with label:  -0.7853809246003358\n",
      "Correlation of Feature 24 with label:  -0.7376137466073733\n",
      "Correlation of Feature 25 with label:  -0.4576025768814218\n",
      "Correlation of Feature 26 with label:  -0.6011420471230111\n",
      "Correlation of Feature 27 with label:  -0.6647554091747947\n",
      "Correlation of Feature 28 with label:  -0.8033085214123192\n",
      "Correlation of Feature 29 with label:  -0.4117245236649108\n",
      "Correlation of Feature 30 with label:  -0.35316689222459274\n"
     ]
    }
   ],
   "source": [
    "# getting the feature-to-label correlations\n",
    "feature_to_label_correlations = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    print('Correlation of Feature ' + str(i + 1) + ' with label: ', np.corrcoef(X_train[:,i], y_train)[0][1])\n",
    "    feature_to_label_correlations.append(abs(np.corrcoef(X_train[:,i], y_train)[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting top 2 features having the highest correlation with the label\n",
    "selected_features = np.argsort(feature_to_label_correlations)[::-1][:2]\n",
    "X_train_selected = X_train[:, selected_features]\n",
    "X_test_selected = X_test[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ..................max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 2/5] END ..................max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 3/5] END ..................max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 4/5] END ..................max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 5/5] END ..................max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV 1/5] END ..................max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV 2/5] END ..................max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 3/5] END ..................max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 4/5] END ..................max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 5/5] END ..................max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV 1/5] END ..................max_depth=3, n_estimators=200; total time=   0.3s\n",
      "[CV 2/5] END ..................max_depth=3, n_estimators=200; total time=   0.3s\n",
      "[CV 3/5] END ..................max_depth=3, n_estimators=200; total time=   0.3s\n",
      "[CV 4/5] END ..................max_depth=3, n_estimators=200; total time=   0.3s\n",
      "[CV 5/5] END ..................max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END ..................max_depth=3, n_estimators=250; total time=   0.4s\n",
      "[CV 2/5] END ..................max_depth=3, n_estimators=250; total time=   0.5s\n",
      "[CV 3/5] END ..................max_depth=3, n_estimators=250; total time=   0.3s\n",
      "[CV 4/5] END ..................max_depth=3, n_estimators=250; total time=   0.3s\n",
      "[CV 5/5] END ..................max_depth=3, n_estimators=250; total time=   0.5s\n",
      "[CV 1/5] END ..................max_depth=3, n_estimators=300; total time=   0.6s\n",
      "[CV 2/5] END ..................max_depth=3, n_estimators=300; total time=   0.5s\n",
      "[CV 3/5] END ..................max_depth=3, n_estimators=300; total time=   0.4s\n",
      "[CV 4/5] END ..................max_depth=3, n_estimators=300; total time=   0.4s\n",
      "[CV 5/5] END ..................max_depth=3, n_estimators=300; total time=   0.4s\n",
      "[CV 1/5] END ..................max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 2/5] END ..................max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 3/5] END ..................max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV 4/5] END ..................max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 5/5] END ..................max_depth=4, n_estimators=100; total time=   0.2s\n",
      "[CV 1/5] END ..................max_depth=4, n_estimators=150; total time=   0.2s\n",
      "[CV 2/5] END ..................max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 3/5] END ..................max_depth=4, n_estimators=150; total time=   0.2s\n",
      "[CV 4/5] END ..................max_depth=4, n_estimators=150; total time=   0.3s\n",
      "[CV 5/5] END ..................max_depth=4, n_estimators=150; total time=   0.2s\n",
      "[CV 1/5] END ..................max_depth=4, n_estimators=200; total time=   0.3s\n",
      "[CV 2/5] END ..................max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV 3/5] END ..................max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV 4/5] END ..................max_depth=4, n_estimators=200; total time=   0.3s\n",
      "[CV 5/5] END ..................max_depth=4, n_estimators=200; total time=   0.3s\n",
      "[CV 1/5] END ..................max_depth=4, n_estimators=250; total time=   0.3s\n",
      "[CV 2/5] END ..................max_depth=4, n_estimators=250; total time=   0.3s\n",
      "[CV 3/5] END ..................max_depth=4, n_estimators=250; total time=   0.3s\n",
      "[CV 4/5] END ..................max_depth=4, n_estimators=250; total time=   0.3s\n",
      "[CV 5/5] END ..................max_depth=4, n_estimators=250; total time=   0.3s\n",
      "[CV 1/5] END ..................max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV 2/5] END ..................max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV 3/5] END ..................max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV 4/5] END ..................max_depth=4, n_estimators=300; total time=   0.5s\n",
      "[CV 5/5] END ..................max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV 1/5] END ..................max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV 2/5] END ..................max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV 3/5] END ..................max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV 4/5] END ..................max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV 5/5] END ..................max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV 1/5] END ..................max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV 2/5] END ..................max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV 3/5] END ..................max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV 4/5] END ..................max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV 5/5] END ..................max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV 1/5] END ..................max_depth=5, n_estimators=200; total time=   0.3s\n",
      "[CV 2/5] END ..................max_depth=5, n_estimators=200; total time=   0.3s\n",
      "[CV 3/5] END ..................max_depth=5, n_estimators=200; total time=   0.3s\n",
      "[CV 4/5] END ..................max_depth=5, n_estimators=200; total time=   0.3s\n",
      "[CV 5/5] END ..................max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END ..................max_depth=5, n_estimators=250; total time=   0.3s\n",
      "[CV 2/5] END ..................max_depth=5, n_estimators=250; total time=   0.3s\n",
      "[CV 3/5] END ..................max_depth=5, n_estimators=250; total time=   0.3s\n",
      "[CV 4/5] END ..................max_depth=5, n_estimators=250; total time=   0.4s\n",
      "[CV 5/5] END ..................max_depth=5, n_estimators=250; total time=   0.4s\n",
      "[CV 1/5] END ..................max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV 2/5] END ..................max_depth=5, n_estimators=300; total time=   0.6s\n",
      "[CV 3/5] END ..................max_depth=5, n_estimators=300; total time=   0.7s\n",
      "[CV 4/5] END ..................max_depth=5, n_estimators=300; total time=   0.7s\n",
      "[CV 5/5] END ..................max_depth=5, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1234),\n",
       "             param_grid={'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [100, 150, 200, 250, 300]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-Fold Grid-Search Cross Validation \n",
    "clf = RandomForestClassifier(random_state = 1234)\n",
    "params = {'n_estimators': [100, 150, 200, 250, 300], 'max_depth': [3, 4, 5]}\n",
    "model_cv = GridSearchCV(estimator = clf, \n",
    "                        cv = 5,\n",
    "                        param_grid = params,\n",
    "                        scoring = 'accuracy',\n",
    "                        verbose = 3)\n",
    "\n",
    "model_cv.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the best parameters\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the Random Forest Classifier Model\n",
    "rf_model = RandomForestClassifier(max_depth = 3, n_estimators = 100, random_state = 1234).fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.868421052631579\n",
      "Accuracy per feature 0.4342105263157895\n"
     ]
    }
   ],
   "source": [
    "# obtaining the Accuracy and Accuracy per feature of the trained Random Forest Classifier Model\n",
    "print('Accuracy', accuracy_score(y_test, rf_model.predict(X_test_selected)))\n",
    "print('Accuracy per feature', accuracy_score(y_test, rf_model.predict(X_test_selected))/X_test_selected.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
